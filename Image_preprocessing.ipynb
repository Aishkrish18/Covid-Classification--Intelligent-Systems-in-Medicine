{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMP0pZG7fyQzHtYNWtJLrKE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nS8Le96XCx7t"},"outputs":[],"source":["\n","import datetime\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import keras_ocr\n","import cv2 as cv\n","import math\n","import numpy as np\n","import skimage\n","from skimage.transform import  rescale,resize\n","from skimage.util import img_as_uint,img_as_ubyte\n","from skimage.color import rgb2gray\n","from skimage import exposure\n","import glob\n","from skimage.filters import threshold_yen"]},{"cell_type":"code","source":["\n","def midpoint(x1, y1, x2, y2):\n","    x_mid = int((x1 + x2)/2)\n","    y_mid = int((y1 + y2)/2)\n","    return (x_mid, y_mid)\n","\n","\n","def remove_text(img_path):\n","    pipeline = keras_ocr.pipeline.Pipeline()\n","\n","    # read image\n","    img = keras_ocr.tools.read(img_path)\n","\n","    # generate (word, box) tuples \n","    prediction_groups = pipeline.recognize([img])\n","    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n","\n","    for box in prediction_groups[0]:\n","        x0, y0 = box[1][0]\n","        x1, y1 = box[1][1] \n","        x2, y2 = box[1][2]\n","        x3, y3 = box[1][3] \n","        \n","        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n","        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n","        \n","        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n","        \n","        cv.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255, thickness)\n","        removed_text_img = cv.inpaint(img, mask, 100, cv.INPAINT_NS)\n","    \n","    #cv.imshow(\"removed text\", img)    \n","\n","    return removed_text_img"],"metadata":{"id":"Xi_DJRyBFAqa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def change_contrast(img, cliplimit: float):\n","    bwimage = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","    clahe = cv.createCLAHE(clipLimit=cliplimit, tileGridSize=(8, 8))\n","    contrast_image = clahe.apply(bwimage)\n","    return contrast_image\n","\n"],"metadata":{"id":"IWqcPR49FAuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gammaCorrection(img, gamma):\n","    invGamma = 1 / gamma\n","\n","    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n","    table = np.array(table, np.uint8)\n","\n","    return cv.LUT(img, table)"],"metadata":{"id":"QWXOCfZYFAyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sharpen(image):\n","  kernel = np.array([[0, -1, 0],\n","                [-1, 5,-1],\n","                [0, -1, 0]])\n","  image_sharp = cv.filter2D(src=image, ddepth=-1, kernel=kernel)\n"],"metadata":{"id":"YVFIeQ0IFA1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def yen(img):\n","  # read image\n","  img = cv.imread(img)\n","  thresh = threshold_yen(img)\n","  # binary = img >= thresh\n","  return thresh"],"metadata":{"id":"-nZ6ZZORFA4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def center_crop(img):\n","    dim = (250, 250)\n","    width, height = img.shape[1], img.shape[0]\n","    # process crop width and height for max available dimension\n","    crop_width = dim[0] if dim[0]<img.shape[1] else img.shape[1]\n","    crop_height = dim[1] if dim[1]<img.shape[0] else img.shape[0] \n","    mid_x, mid_y = int(width/2), int(height/2)\n","    cw2, ch2 = int(crop_width/2), int(crop_height/2) \n","    crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n","    return crop_img"],"metadata":{"id":"G-LX_eBWFA6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scale_image(img, factor=1):\n","  #Returns resize image by scale factor\n","  return cv.resize(img,(int(img.shape[1]*factor), int(img.shape[0]*factor)))"],"metadata":{"id":"QMqQZ6DHbs6j"},"execution_count":null,"outputs":[]}]}